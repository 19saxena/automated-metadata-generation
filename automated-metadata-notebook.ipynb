{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c110b9a6-8567-4ee0-a743-aa6679e7b959",
   "metadata": {},
   "source": [
    "**NOTEBOOK-BASED METADATA GENERATOR: RUNS LOCALLY ON CPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35215ab9-d78d-46c0-944e-8efd155595e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(\"‚úÖ NumPy version:\", np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e0fb58-3a0a-49f0-8cda-300fdc95f2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet \\\n",
    "    transformers \\\n",
    "    pytesseract \\\n",
    "    torch \\\n",
    "    nltk \\\n",
    "    pillow \\\n",
    "    python-docx \\\n",
    "    pymupdf \\\n",
    "    sentencepiece \\\n",
    "    keybert \\\n",
    "    sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff53e3-159c-4998-8332-da97fba1c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import fitz\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from transformers import pipeline\n",
    "import docx\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# NLTK setup\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Text Extraction\n",
    "def extract_text(file_input):\n",
    "    ext = file_input.name.split('.')[-1].lower()\n",
    "    file_data = file_input.read()\n",
    "    file_input.seek(0)\n",
    "    if ext == 'pdf':\n",
    "        with fitz.open(stream=file_data, filetype=\"pdf\") as doc:\n",
    "            return \"\\n\".join(p.get_text() for p in doc)\n",
    "    elif ext == 'docx':\n",
    "        d = docx.Document(BytesIO(file_data))\n",
    "        return \"\\n\".join(p.text for p in d.paragraphs)\n",
    "    elif ext == 'txt':\n",
    "        return file_data.decode(\"utf-8\", errors=\"ignore\")\n",
    "    else:\n",
    "        return \"Unsupported file\"\n",
    "\n",
    "# Clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# Summarization\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "def summarize_text(text):\n",
    "    chunks = [text[i:i+1000] for i in range(0, len(text), 1000)][:2]\n",
    "    summaries = [summarizer(chunk)[0]['summary_text'] for chunk in chunks]\n",
    "    return \" \".join(summaries)\n",
    "\n",
    "# Keywords\n",
    "def extract_keywords(text):\n",
    "    words = re.findall(r'\\w+', text.lower())\n",
    "    stop = set(stopwords.words('english'))\n",
    "    filtered = [w for w in words if w not in stop and len(w) > 3]\n",
    "    return [w for w, _ in Counter(filtered).most_common(10)]\n",
    "\n",
    "# Final metadata function\n",
    "def generate_metadata(file_input):\n",
    "    text = extract_text(file_input)\n",
    "    text = clean_text(text)\n",
    "    summary = summarize_text(text)\n",
    "    title = summary.split('.')[0]\n",
    "    keywords = extract_keywords(text)\n",
    "    return {\n",
    "        \"üìå Title\": title,\n",
    "        \"üìÑ Summary\": summary,\n",
    "        \"üè∑Ô∏è Keywords\": keywords\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c294933-7f79-48f1-b817-a4ef34cd29c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import FileUpload\n",
    "from IPython.display import display\n",
    "import io\n",
    "\n",
    "def upload_file_widget():\n",
    "    uploader = FileUpload(accept='.pdf,.docx,.txt', multiple=False)\n",
    "    display(uploader)\n",
    "    \n",
    "    def get_file():\n",
    "        if uploader.value:\n",
    "            for fname, item in uploader.value.items():\n",
    "                print(f\"üìÇ Uploaded: {fname}\")\n",
    "                return io.BytesIO(item['content']), fname\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Please upload a file.\")\n",
    "            return None, None\n",
    "\n",
    "    return uploader, get_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fba782c-fe6c-4baf-9c01-eae7e15799f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploader, get_file = upload_file_widget()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac9e525-4609-4d14-a95d-9f07a897b390",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_obj, filename = get_file()\n",
    "if file_obj:\n",
    "    file_obj.name = filename  \n",
    "    metadata = generate_metadata(file_obj)\n",
    "    print(metadata)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
